{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/issei/DaedalusForge/blob/main/Notebook_de_Prospec%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633fc2df",
        "outputId": "85722ad8-735a-44d7-f864-3df7df07814a"
      },
      "source": [
        "# @title 1. Setup: Instalação de Bibliotecas\n",
        "# Descrição: Esta célula inicial prepara o ambiente do Google Colab\n",
        "# instalando todas as dependências necessárias para o projeto.\n",
        "# A opção '-q' (quiet) reduz a quantidade de logs de instalação.\n",
        "\n",
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai httpx\n",
        "!pip install -q pandas==2.2.2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55daec9f",
        "outputId": "810e7481-15bf-495b-93c2-da119ff2f94e"
      },
      "source": [
        "# @title 2. Configuração: Importações e Carregamento de Chaves de API\n",
        "# Descrição: Aqui, importamos todos os módulos que serão utilizados e, mais\n",
        "# importante, carregamos as chaves de API (secrets) que você configurou\n",
        "# no ambiente do Colab. A execução do notebook será interrompida se\n",
        "# as chaves não forem encontradas.\n",
        "\n",
        "import time\n",
        "from typing import List, Dict, Any\n",
        "from google.colab import userdata\n",
        "\n",
        "import httpx\n",
        "import pandas as pd\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso.\")\n",
        "\n",
        "# Carregamento seguro das chaves de API\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    APOLLO_API_KEY = userdata.get('APOLLO_API_KEY')\n",
        "    print(\"✅ Chaves de API carregadas com sucesso do Colab Secrets!\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"🛑 Erro: Chaves de API não encontradas. Por favor, configure 'GOOGLE_API_KEY' e 'APOLLO_API_KEY' nos Secrets do Colab (ícone de chave no menu à esquerda).\")\n",
        "    # Interrompe a execução se as chaves não forem encontradas\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"❌ Ocorreu um erro inesperado ao carregar as chaves: {e}\")\n",
        "    raise"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso.\n",
            "✅ Chaves de API carregadas com sucesso do Colab Secrets!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b59e0255",
        "outputId": "4c5c3cea-3ff6-4bfa-8522-9ecf7fa08cc4"
      },
      "source": [
        "# @title 3. Arquitetura: Definição das Estruturas e Agentes\n",
        "# Descrição: Esta célula contém o núcleo intelectual do nosso sistema.\n",
        "# Definimos a estrutura de dados que o LLM deve gerar (ApolloQuery) e\n",
        "# implementamos as classes para cada um dos cinco agentes especializados\n",
        "# que compõem nosso pipeline A2A (Agent-to-Agent).\n",
        "\n",
        "# --- Estrutura de Dados para o LLM ---\n",
        "class ApolloQuery(BaseModel):\n",
        "    \"\"\"Define o formato JSON esperado pela API do Apollo.io para a busca de pessoas.\"\"\"\n",
        "    q_person_titles: List[str] = Field(default_factory=list, description=\"Lista de cargos. Ex: ['Marketing Manager']\")\n",
        "    person_locations: List[str] = Field(default_factory=list, description=\"Lista de localizações. Ex: ['Brazil']\")\n",
        "    organization_num_employees_ranges: List[str] = Field(default_factory=list, description=\"Faixas de tamanho da empresa. Ex: ['11,50']\")\n",
        "    q_organization_keyword_tags: List[str] = Field(default_factory=list, description=\"Palavras-chave da organização. Ex: ['education']\")\n",
        "\n",
        "# --- Implementação dos Agentes ---\n",
        "class InputAgent:\n",
        "    \"\"\"Agente 1: Define os critérios de busca.\"\"\"\n",
        "    def get_criteria(self) -> str:\n",
        "        print(\"🕵️ Agente 1: Definindo critérios de busca de leads.\")\n",
        "        return \"Preciso de leads que trabalham com marketing ou são gerentes de marketing, localizados no Brasil, em empresas de educação ou edtech com 11 a 50 funcionários.\"\n",
        "\n",
        "class QueryGenerationAgent:\n",
        "    \"\"\"Agente 2: Usa o Gemini para traduzir os critérios em um payload de API.\"\"\"\n",
        "    def __init__(self, api_key: str):\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=api_key, temperature=0)\n",
        "        structured_llm = llm.with_structured_output(ApolloQuery)\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"Você é um especialista em gerar payloads para a API do Apollo.io. Converta a solicitação do usuário em um JSON estruturado para o endpoint /v1/people/search, mapeando os critérios para os campos corretos. Retorne apenas o objeto JSON.\"),\n",
        "            (\"human\", \"{user_request}\")\n",
        "        ])\n",
        "        self.chain = prompt | structured_llm\n",
        "\n",
        "    def generate_query(self, criteria: str) -> Dict[str, Any]:\n",
        "        print(\"🤖 Agente 2: Gerando payload para a API Apollo com o Gemini...\")\n",
        "        query_payload = self.chain.invoke({\"user_request\": criteria})\n",
        "        print(\"✅ Payload gerado:\", query_payload.dict())\n",
        "        return query_payload.dict()\n",
        "\n",
        "class ApolloAPIAgent:\n",
        "    \"\"\"Agente 3: Interage com a API do Apollo.io e lida com a paginação.\"\"\"\n",
        "    BASE_URL = \"https://api.apollo.io/v1/people/search\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.api_key = api_key\n",
        "\n",
        "    def fetch_leads(self, query_payload: Dict[str, Any], max_leads: int = 500) -> List[Dict[str, Any]]:\n",
        "        all_leads, page, per_page = [], 1, 100\n",
        "        # Define os cabeçalhos da requisição, incluindo a chave da API\n",
        "        headers = {\n",
        "            \"X-Api-Key\": self.api_key,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        print(f\"\\n📞 Agente 3: Iniciando busca de até {max_leads} leads na API do Apollo...\")\n",
        "        while len(all_leads) < max_leads:\n",
        "            payload = {\"api_key\": self.api_key, \"page\": page, \"per_page\": per_page, **query_payload}\n",
        "            try:\n",
        "                with httpx.Client() as client:\n",
        "                    response = client.post(self.BASE_URL, json=payload, headers=headers, timeout=30.0)\n",
        "                    response.raise_for_status()\n",
        "                data = response.json()\n",
        "                leads_on_page = data.get(\"people\", [])\n",
        "                if not leads_on_page:\n",
        "                    print(\"🏁 Não foram encontrados mais leads. Fim da busca.\")\n",
        "                    break\n",
        "                all_leads.extend(leads_on_page)\n",
        "                print(f\"📄 Página {page}: {len(leads_on_page)} leads encontrados. Total: {len(all_leads)}\")\n",
        "                page += 1\n",
        "                time.sleep(1)\n",
        "            except httpx.HTTPStatusError as e:\n",
        "                print(f\"❌ Erro na API do Apollo: {e.response.status_code} - {e.response.text}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Ocorreu um erro inesperado: {e}\")\n",
        "                break\n",
        "        return all_leads[:max_leads]\n",
        "\n",
        "class DeduplicationAgent:\n",
        "    \"\"\"Agente 4: Remove duplicatas da lista de leads.\"\"\"\n",
        "    def remove_duplicates(self, leads: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "        print(\"\\n🧼 Agente 4: Removendo leads duplicados com base no email...\")\n",
        "        unique_leads, seen_emails = [], set()\n",
        "        for lead in leads:\n",
        "            email = lead.get(\"email\")\n",
        "            if email and email not in seen_emails:\n",
        "                unique_leads.append(lead)\n",
        "                seen_emails.add(email)\n",
        "        print(f\"✨ Leads únicos: {len(unique_leads)} (de {len(leads)} brutos)\")\n",
        "        return unique_leads\n",
        "\n",
        "class CSVExportAgent:\n",
        "    \"\"\"Agente 5: Exporta os leads únicos para um arquivo CSV.\"\"\"\n",
        "    def export(self, leads: List[Dict[str, Any]], filename: str = \"leads_apollo.csv\"):\n",
        "        print(f\"\\n💾 Agente 5: Exportando leads para o arquivo '{filename}'...\")\n",
        "        if not leads:\n",
        "            print(\"⚠️ Nenhum lead para exportar.\")\n",
        "            return\n",
        "        relevant_data = [{\n",
        "            \"nome_completo\": l.get(\"name\"), \"primeiro_nome\": l.get(\"first_name\"),\n",
        "            \"ultimo_nome\": l.get(\"last_name\"), \"email\": l.get(\"email\"),\n",
        "            \"cargo\": l.get(\"title\"), \"empresa\": l.get(\"organization\", {}).get(\"name\"),\n",
        "            \"url_linkedin\": l.get(\"linkedin_url\"), \"localizacao\": l.get(\"headline\"),\n",
        "        } for l in leads]\n",
        "        df = pd.DataFrame(relevant_data)\n",
        "        df.to_csv(filename, index=False, encoding='utf-8')\n",
        "        print(f\"✅ Arquivo '{filename}' salvo com {len(df)} leads. Verifique no painel de arquivos.\")\n",
        "\n",
        "print(\"Definições dos Agentes carregadas com sucesso.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definições dos Agentes carregadas com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21df625b",
        "outputId": "6c00d258-a22e-49c7-f640-536ba1051ddc"
      },
      "source": [
        "# @title 4. Execução: Orquestração do Pipeline A2A\n",
        "# Descrição: Esta é a célula de execução principal. Ao ser rodada, ela\n",
        "# instanciará cada agente e os orquestrará na sequência correta para\n",
        "# completar a tarefa de prospecção de ponta a ponta.\n",
        "\n",
        "def run_prospector_pipeline(google_key: str, apollo_key: str):\n",
        "    \"\"\"Orquestra a interação entre os agentes para executar o pipeline completo.\"\"\"\n",
        "    if not google_key or not apollo_key:\n",
        "        print(\"🛑 Erro fatal: Chaves de API não foram passadas para o pipeline.\")\n",
        "        return\n",
        "\n",
        "    # 1. Instanciar os agentes\n",
        "    print(\"--- INICIANDO PIPELINE DE PROSPECÇÃO A2A ---\")\n",
        "    input_agent = InputAgent()\n",
        "    query_gen_agent = QueryGenerationAgent(api_key=google_key)\n",
        "    apollo_agent = ApolloAPIAgent(api_key=apollo_key)\n",
    dedup_agent = DeduplicationAgent()
        "    export_agent = CSVExportAgent()\n",
        "\n",
        "    # 2. Executar o pipeline A2A em sequência\n",
        "    search_criteria = input_agent.get_criteria()\n",
        "    apollo_payload = query_gen_agent.generate_query(search_criteria)\n",
        "    raw_leads = apollo_agent.fetch_leads(apollo_payload, max_leads=500)\n",
        "    unique_leads = dedup_agent.remove_duplicates(raw_leads)\n",
        "    export_agent.export(unique_leads)\n",
        "\n",
        "    print(\"\\n🎉 Processo de prospecção concluído com sucesso! 🎉\")\n",
        "\n",
        "# Ponto de entrada que verifica a existência das chaves antes de rodar\n",
        "if 'GOOGLE_API_KEY' in globals() and GOOGLE_API_KEY and 'APOLLO_API_KEY' in globals() and APOLLO_API_KEY:\n",
        "    run_prospector_pipeline(google_key=GOOGLE_API_KEY, apollo_key=APOLLO_API_KEY)\n",
        "else:\n",
        "    print(\"🛑 Pipeline não executado. Verifique se as chaves de API foram carregadas corretamente na Célula 2.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- INICIANDO PIPELINE DE PROSPECÇÃO A2A ---\n",
            "🕵️ Agente 1: Definindo critérios de busca de leads.\n",
            "🤖 Agente 2: Gerando payload para a API Apollo com o Gemini...\n",
            "✅ Payload gerado: {'q_person_titles': ['Marketing', 'Marketing Manager'], 'person_locations': ['Brazil'], 'organization_num_employees_ranges': ['11,50'], 'q_organization_keyword_tags': ['education', 'edtech']}\n",
            "\n",
            "📞 Agente 3: Iniciando busca de até 500 leads na API do Apollo...\n",
            "❌ Erro na API do Apollo: 403 - {\"error\":\"api/v1/people/search is not accessible with this api_key on a free plan. Please upgrade your plan from https://app.apollo.io/.\",\"error_code\":\"API_INACCESSIBLE\"}\n",
            "\n",
            "🧼 Agente 4: Removendo leads duplicados com base no email...\n",
            "✨ Leads únicos: 0 (de 0 brutos)\n",
            "\n",
            "💾 Agente 5: Exportando leads para o arquivo 'leads_apollo.csv'...\n",
            "⚠️ Nenhum lead para exportar.\n",
            "\n",
            "🎉 Processo de prospecção concluído com sucesso! 🎉\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
